{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as db \n",
    "import pandas as pd\n",
    "conn = db.connect('soccer/database.sqlite')\n",
    "\n",
    "##\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "std = StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_team_name = {}\n",
    "norm_team_name['Man United'] = 'Manchester United'\n",
    "norm_team_name['Man City'] = 'Manchester City'\n",
    "norm_team_name['QPR'] = 'Queens Park Rangers'\n",
    "norm_team_name['West Brom'] = 'West Bromwich Albion'\n",
    "norm_team_name['West Ham'] = 'West Ham United'\n",
    "norm_team_name['Bournemouth'] = 'AFC Bournemouth'\n",
    "\n",
    "year_data = {'2014': 'statbunker-football-stats/Player Stats 2014-15.csv' , \n",
    "             '2015': 'statbunker-football-stats/Player Stats 2015-16.csv' ,\n",
    "             '2016': 'statbunker-football-stats/Player Stats 2016-17.csv'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_players_info(year):\n",
    "    query_str = \"\"\"select  p.player_name,pa2.* from player_attributes pa2, player p where p.player_api_id = pa2.player_api_id and\n",
    "    (pa2.player_api_id, pa2.date) in (\n",
    "    select z.player_api_id, z.date from (\n",
    "    select pa.player_api_id, pa.date, min(abs(strftime('%%s',pa.date) - strftime('%%s','%(year)s-09-01 00:00:00'))) from player_attributes pa, player p \n",
    "                                    where pa.player_api_id = p.player_api_id\n",
    "                                    and strftime('%%s',pa.date) > strftime('%%s','2014-05-14 00:00:00') \n",
    "                                    and pa.date like '%(year)s%%'\n",
    "                                    group by pa.player_api_id ) z )\"\"\"%{'year':year}\n",
    "    \n",
    "    all_player_attrs = pd.read_sql_query(query_str,conn)\n",
    "    \n",
    "    return all_player_attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_player_names(all_players_info):\n",
    "    \n",
    "    for key,value in norm_team_name.items():\n",
    "        all_players_info.loc[lambda df: df['HomeTeam'] == key, 'HomeTeam'] = value\n",
    "        all_players_info.loc[lambda df: df['AwayTeam'] == key, 'AwayTeam'] = value\n",
    "    \n",
    "    return all_players_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_data(year):\n",
    "    ptm = pd.read_csv(year_data[year] , dtype = {'overall_rating':float} )\n",
    "   \n",
    "    ptm = ptm[(ptm['Type Of Goal'] == 'Player') & (ptm['League'] == 'Premier League')]\n",
    "    \n",
    "    all_players_info  = get_all_players_info(year)\n",
    "        \n",
    "    joined = all_players_info.set_index('player_name').join(ptm.set_index('Player'), how='inner')\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team(data, name):\n",
    "    \n",
    "    full_team = data[data['Team'].str.startswith(name)]\n",
    "        \n",
    "    team_agg = {}\n",
    "    \n",
    "    team_df = {}\n",
    "    \n",
    "    df_start = full_team[full_team['Team'] == 'THIS DOES NOT EXIST']\n",
    "    \n",
    "    pos_sel = {'Defender': 4, 'Midfielder': 4, 'Forward': 2, 'Goalkeeper':1}\n",
    "\n",
    "    \n",
    "    \n",
    "#     if (len(df_start[df_start['Position'] == 'Forward']) < 3 ):\n",
    "#         forwards = len(df_start[df_start['Position'] == 'Forward'])\n",
    "#         print(forwards)\n",
    "#         pos_sel['Forward'] = forwards\n",
    "#         pos_sel['Midfielder'] = 6 - forwards\n",
    "\n",
    "    for key,value in pos_sel.items():\n",
    "        \n",
    "        grp = full_team[full_team['Position'] == key].sort_values(by = ['overall_rating'], ascending = False).head(value)\n",
    "        df_start = df_start.append(grp)\n",
    "        avg = grp.mean()\n",
    "        team_agg[key] = avg\n",
    "    \n",
    "    return df_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_attributes(team):\n",
    "    #team[team['Position'] == 'Goalkeeper']['Position'] = 'Defender'\n",
    "    \n",
    "    team.loc[lambda df: df['Position'] == 'Goalkeeper', 'Position'] = 'Defender'\n",
    "       \n",
    "    \n",
    "    g = team.groupby(['Position'] , as_index=False).mean()\n",
    "    #print(g['overall_rating'])\n",
    "    #g = g.reset_index().set_index('index')\n",
    "    \n",
    "    return g.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixtures(year):\n",
    "    f = pd.read_csv('epl-results-19932018/EPL_Set.csv')\n",
    "    f = norm_player_names(f)\n",
    "    \n",
    "    return f[f['Season'].str.startswith(year)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_metrics_2(row, home_attrs,away_attrs,i):\n",
    "    ### D - D , A - A ###\n",
    "    norm_attrs = {}\n",
    "    norm_attrs['Home_Def'] = home_attrs[0]['overall_rating']\n",
    "    norm_attrs['Home_Att'] = home_attrs[1]['overall_rating']\n",
    "    norm_attrs['Home_Mid'] = home_attrs[2]['overall_rating']\n",
    "    \n",
    "    norm_attrs['Away_Def'] = away_attrs[0]['overall_rating']\n",
    "    norm_attrs['Away_Att'] = away_attrs[1]['overall_rating']\n",
    "    norm_attrs['Away_Mid'] = away_attrs[2]['overall_rating']\n",
    "\n",
    "    norm_attrs['Def_Score'] = home_attrs[0]['overall_rating'] - away_attrs[0]['overall_rating']\n",
    "    norm_attrs['Att_Score'] = home_attrs[1]['overall_rating'] - away_attrs[1]['overall_rating']\n",
    "    norm_attrs['Mid_Score'] = home_attrs[2]['overall_rating'] - away_attrs[2]['overall_rating']\n",
    "    norm_attrs['Result'] = 1 if row['FTHG'] - row['FTAG'] > 0  else (-1 if row['FTHG'] - row['FTAG'] < 0 else 0)\n",
    "    \n",
    "    norm_df = pd.DataFrame(norm_attrs, index = [str(i)])\n",
    "    \n",
    "    return norm_df\n",
    "\n",
    "def combine_metrics_1(row,home_attrs,away_attrs,i):\n",
    "    \"\"\" D-A  \"\"\"\n",
    "    norm_attrs = {}\n",
    "    \n",
    "    norm_attrs['Home_Def'] = home_attrs[0]['overall_rating']\n",
    "    norm_attrs['Home_Att'] = home_attrs[1]['overall_rating']\n",
    "    norm_attrs['Home_Mid'] = home_attrs[2]['overall_rating']\n",
    "    \n",
    "    norm_attrs['Away_Def'] = away_attrs[0]['overall_rating']\n",
    "    norm_attrs['Away_Att'] = away_attrs[1]['overall_rating']\n",
    "    norm_attrs['Away_Mid'] = away_attrs[2]['overall_rating']\n",
    "    \n",
    "    norm_attrs['Def_Score'] = home_attrs[0]['overall_rating'] - away_attrs[1]['overall_rating']\n",
    "    norm_attrs['Att_Score'] = home_attrs[1]['overall_rating'] - away_attrs[0]['overall_rating']\n",
    "    norm_attrs['Mid_Score'] = home_attrs[2]['overall_rating'] - away_attrs[2]['overall_rating']\n",
    "    norm_attrs['Result'] = 1 if row['FTHG'] - row['FTAG'] > 0  else (-1 if row['FTHG'] - row['FTAG'] < 0 else 0)\n",
    "    \n",
    "    norm_df = pd.DataFrame(norm_attrs, index = [str(i)])\n",
    "    \n",
    "    return norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_team_data(year):\n",
    "    \n",
    "    data = {}\n",
    "\n",
    "    joined_data = get_full_data(year)\n",
    "\n",
    "    f = get_fixtures(year)\n",
    "    teams = f['HomeTeam'].unique()\n",
    "\n",
    "    for team in teams:\n",
    "        team_data = create_team(joined_data, team)\n",
    "        team_attr = agg_attributes(team_data)\n",
    "        data[team] = (team_data, team_attr)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_normalize(df, attr,column):\n",
    "        \n",
    "    mx = max(df[column])\n",
    "    mn = min(df[column])\n",
    "    diff = (mx) - (mn)\n",
    "    return df[attr].apply(lambda x : x/diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_training_data(years):\n",
    "    \n",
    "    full_res_df = pd.DataFrame()\n",
    "    \n",
    "    for year in years:\n",
    "        \n",
    "        team_store = get_all_team_data(year)\n",
    "        i = 0\n",
    "        res_df = pd.DataFrame()\n",
    "        f = get_fixtures(year)\n",
    "        for key,row in f.iterrows():\n",
    "        #     print(\"MATCHING UP: %s vs %s\"%(row['HomeTeam'], row['AwayTeam']))\n",
    "            home = row['HomeTeam']\n",
    "            away = row['AwayTeam']\n",
    "\n",
    "            home_attrs = team_store[home][1]\n",
    "            away_attrs = team_store[away][1]\n",
    "\n",
    "            res_df = res_df.append(combine_metrics_2(row,home_attrs,away_attrs,i))\n",
    "\n",
    "            i = i + 1\n",
    "        \n",
    "        res_df['Att_Score'] = attr_normalize(res_df, 'Att_Score','Home_Att' )\n",
    "        res_df['Def_Score'] = attr_normalize(res_df, 'Def_Score','Home_Def' )\n",
    "        res_df['Mid_Score'] = attr_normalize(res_df, 'Mid_Score','Home_Mid' )\n",
    "        res_df['Total'] = (res_df['Att_Score'] + res_df['Def_Score'] + res_df['Mid_Score'])/3\n",
    "#         res_df.pop('Home_Att')\n",
    "#         res_df.pop('Home_Mid')\n",
    "#         res_df.pop('Home_Def')\n",
    "#         res_df.pop('Away_Att')\n",
    "#         res_df.pop('Away_Mid')\n",
    "#         res_df.pop('Away_Def')\n",
    "\n",
    "        \n",
    "        full_res_df = full_res_df.append(res_df)\n",
    "\n",
    "    return full_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d1c0d87a9aec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtr_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2014'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2015'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2016'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtr_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Away_Att'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Away_Att'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "tr_data = construct_training_data(['2014','2015','2016'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b2694db31b9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtr_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Away_Att'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Away_Att'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "tr_data['Away_Att'] = std.fit_transform(tr_data['Away_Att'])\n",
    "print(tr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "attribute = 'Total'\n",
    "\n",
    "strong_home_winners = tr_data[(tr_data['Total'] > 0) & (tr_data['Result'] == 1)]\n",
    "\n",
    "strong_home_losers= tr_data[(tr_data['Total'] > 0) & (tr_data['Result'] == -1)]\n",
    "\n",
    "strong_home_draw = tr_data[(tr_data['Total'] > 0) &  (tr_data['Result'] == 0)]\n",
    "\n",
    "\n",
    "strong_away_winners = tr_data[(tr_data['Total'] < 0) & (tr_data['Result'] == 1)]\n",
    "\n",
    "strong_away_losers = tr_data[(tr_data['Total'] < 0) & (tr_data['Result'] == -1)]\n",
    "\n",
    "strong_away_draw = tr_data[(tr_data['Total'] < 0) &  (tr_data['Result'] == 0)]\n",
    "\n",
    "\n",
    "disp_attrs = {'hist': True, 'kde': True, 'norm_hist':True, \"color\" : 'black', 'rug':True}\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(3, 2, figsize=(13, 7), sharex=False)\n",
    "\n",
    "sns.distplot(strong_home_winners[attribute],**disp_attrs, ax = axes[0,0] )\n",
    "axes[0,0].set_title( 'Games where strong home team won - %s of 1140 '%str(len(strong_home_winners['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_home_losers[attribute],**disp_attrs, ax = axes[1,0])\n",
    "axes[1,0].set_title( 'Distribution where strong home team lost - %s of 1140'%str(len(strong_home_losers['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_home_draw[attribute],**disp_attrs, ax = axes[2,0])\n",
    "axes[2,0].set_title( 'Distribution where strong home team drew - %s of 1140'%str(len(strong_home_draw['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_away_winners[attribute],**disp_attrs,ax = axes[0,1] )\n",
    "axes[0,1].set_title( 'Games where strong away teams won - %s of 1140'%str(len(strong_away_winners['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_away_losers[attribute],**disp_attrs, ax = axes[1,1])\n",
    "axes[1,1].set_title( 'Distribution where strong away teams lost - %s of 1140'%str(len(strong_away_losers['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_away_draw[attribute],**disp_attrs, ax = axes[2,1])\n",
    "axes[2,1].set_title( 'Distribution where strong away team drew - %s of 1140'%str(len(strong_away_draw['Att_Score'])))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# for key, row in tr_data.iterrows():\n",
    "    \n",
    "#     if (row['Def_Score'] > 0 and row['Result'] == 1) or (row['Def_Score'] < 0 and row['Result'] == -1):\n",
    "#         color = ''\n",
    "        \n",
    "#     elif row['Result'] == 0:\n",
    "#         color = ''\n",
    "#     else:\n",
    "#         color = 'bx'\n",
    " \n",
    "#     plt.plot(key, row['Att_Score'], color)\n",
    "\n",
    "# plt.show()\n",
    "# attr = ['Att_Score','Def_Score','Mid_Score']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for a in enumerate(attr):\n",
    "#     print(\"Based on attribute %s\"%a)\n",
    "#     strong_winners_home = tr_data[(tr_data[a] > 0) & (tr_data['Result'] == 1)]\n",
    "#     strong_winners_away = tr_data[(tr_data[a] < 0) & (tr_data['Result'] == -1)]\n",
    "\n",
    "    \n",
    "#     plt.plot(i,tr_data['Att_Score'],'bo',label = 'Test')\n",
    "#     strong_draw_home = tr_data[(tr_data[a] > 0) & (tr_data['Result'] == 0)]\n",
    "#     strong_draw_away = tr_data[(tr_data[a] < 0) & (tr_data['Result'] == 0)]\n",
    "    \n",
    "#     weak_winner_home = tr_data[(tr_data[a] > 0) & (tr_data['Result'] == -1)]\n",
    "#     weak_winner_away = tr_data[(tr_data[a] < 0) & (tr_data['Result'] == 1)]\n",
    " \n",
    "# #     print(len(strong_winners_away) + len(strong_winners_home) )\n",
    "\n",
    "# #     #print(strong_winners_home\n",
    "# #     print(len(strong_draw_home) + len(strong_draw_away))\n",
    "    \n",
    "# #     print(len(weak_winner_away) + len(weak_winner_home) )\n",
    "    \n",
    "    \n",
    "# #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train,y_train):\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    #Input Layer with 61 inputs corresponding to 61 features \n",
    "    \n",
    "    model.add(Dense(1,input_dim=3,activation='relu'))\n",
    "    model.add(Dense(2,activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1,activation='softmax'))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "#     model.add(Dense(20,input_dim = 3, activation = 'relu'))\n",
    "\n",
    "#     model.add(Dense(128,activation = 'relu'))\n",
    "\n",
    "#     model.add(Dense(1,activation = 'sigmoid'))\n",
    "  \n",
    "#     #Compiling the model with appropriate parameters\n",
    "#     model.compile(loss = 'mse', optimizer ='adam',metrics = ['accuracy'])\n",
    "\n",
    "    result = model.fit(x_train,y_train,epochs = 50, batch_size = 50)\n",
    "\n",
    "    #Store the model, its average training accuracy and validation accuracy over 10 epochs\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_copy = tr_data.copy()\n",
    "print(full_copy)\n",
    "full_copy.pop('Total')\n",
    "full_y = full_copy.pop('Result')\n",
    "full_x = full_copy\n",
    "\n",
    "x_train,te_x,y_train,te_y = train_test_split(full_x, full_y, test_size = 0.25, stratify = full_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training neural network\n",
    "print(len(x_train))\n",
    "model = create_model(x_train,y_train)\n",
    "#pred_y = model.predict(te_x)\n",
    "score = model.evaluate(te_x,te_y)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm = LinearSVC(C = 0.1)\n",
    "svm.fit(x_train,y_train)\n",
    "# print(svm.coef_)\n",
    "# print(svm.intercept_)\n",
    "y_pred = svm.predict(te_x)\n",
    "z =accuracy_score(te_y,y_pred)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4, random_state = 5)\n",
    "\n",
    "dt.fit(x_train['Att_Score'].values.reshape(-1,1),y_train)\n",
    "\n",
    "y_pred = dt.predict(te_x['Att_Score'].values.reshape(-1,1))\n",
    "\n",
    "a = accuracy_score(te_y,y_pred)\n",
    "print(a)\n",
    "# print(te_y.values)\n",
    "print(y_pred)\n",
    "\n",
    "confusion_matrix(y_pred, te_y, labels = [1,0,-1])\n",
    "\n",
    "# import graphviz \n",
    "\n",
    "\n",
    "# dot_data = tree.export_graphviz(dt, out_file='test',feature_names = ['Att_Score'] ,class_names = ['0','-1','1'])\n",
    "\n",
    "# graphviz.render('dot','png','test', quiet = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Gaussian NB\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "\n",
    "gnb.fit(x_train['Att_Score'].values.reshape(-1,1),y_train)\n",
    "\n",
    "y_pred = gnb.predict(te_x['Att_Score'].values.reshape(-1,1))\n",
    "\n",
    "ac = accuracy_score(te_y,y_pred)\n",
    "print(ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

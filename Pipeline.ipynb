{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models import keras_1, keras_2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import *\n",
    "from evaluation import *\n",
    "from common import *\n",
    "# train a feats model\n",
    "from gen_feats_data import get_feats_data\n",
    "from gen_fieldpos_data import get_fieldpos_data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, SelectKBest , chi2, mutual_info_classif,SelectPercentile\n",
    "\n",
    "def feature_selection_evaluation(tr_data,val_data,k_values, keras_model):\n",
    "    accuracies = []\n",
    "    \n",
    "    for kval in k_values:\n",
    "        \n",
    "        kbest = SelectKBest(k = kval)\n",
    "        \n",
    "        feat_sel_tr_data = kbest.fit_transform(tr_data[0],tr_data[1])\n",
    "        \n",
    "        feat_sel_val_data = kbest.transform(val_data[0])\n",
    "\n",
    "        #get all the selected features and apply them to the validation data \n",
    "\n",
    "        model = keras_model(feat_sel_tr_data,onehot(tr_data[1]),(feat_sel_val_data,onehot(val_data[1])))\n",
    "        val_accuracy =  model.evaluate(feat_sel_val_data,onehot(val_data[1]))[1] #only accuracy\n",
    "        accuracies.append(val_accuracy)\n",
    "        print(kval, val_accuracy)\n",
    "        # Get idxs of columns to keep\n",
    "        cols = kbest.get_support(indices=True)\n",
    "        # Create new dataframe with only desired columns, or overwrite existing\n",
    "        sel_cols = [tr_data[0].columns[ic] for ic in cols]\n",
    "        print(sel_cols)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, SelectKBest , chi2, mutual_info_classif,SelectPercentile\n",
    "\n",
    "def feature_selection_pca(tr_data,val_data,k_values, keras_model):\n",
    "    accuracies = []\n",
    "    \n",
    "    for kval in k_values:\n",
    "        \n",
    "        kbest = SelectKBest( k = kval)\n",
    "        \n",
    "        feat_sel_tr_data = kbest.fit_transform(tr_data[0],tr_data[1])\n",
    "        \n",
    "        feat_sel_val_data = kbest.transform(val_data[0])\n",
    "\n",
    "        #get all the selected features and apply them to the validation data \n",
    "\n",
    "        model = keras_model(feat_sel_tr_data,onehot(tr_data[1]),(feat_sel_val_data,onehot(val_data[1])))\n",
    "        val_accuracy =  model.evaluate(feat_sel_val_data,onehot(val_data[1]))[1] #only accuracy\n",
    "        accuracies.append(val_accuracy)\n",
    "        print(kval, val_accuracy)\n",
    "        # Get idxs of columns to keep\n",
    "        cols = kbest.get_support()\n",
    "        # Create new dataframe with only desired columns, or overwrite existing\n",
    "        print(cols)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_layers_model(feats_tr,field_pos_tr):\n",
    "#     import keras\n",
    "\n",
    "#     input1 = keras.layers.Input(shape=(feats_tr[0].shape[1],))\n",
    "#     x1 = keras.layers.Dense(50, activation='sigmoid')(input1)\n",
    "#     input2 = keras.layers.Input(shape=(field_pos_tr.shape[1],))\n",
    "#     x2 = keras.layers.Dense(50, activation='sigmoid')(input2)\n",
    "#     # equivalent to added = keras.layers.add([x1, x2])\n",
    "#     added = keras.layers.Add()([x1, x2])\n",
    "\n",
    "#     out = keras.layers.Dense(4)(added)\n",
    "#     model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
    "    \n",
    "    \n",
    "#     model = Model(input=[inp1, inp2, inp3, inp4], output=op)\n",
    "#     model.compile(optimizer='rmsprop',\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "#     model.fit([train1,train2,train3,train4], y_train,\n",
    "#               nb_epoch=10, batch_size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_tr_data = get_feats_data(['2014','2015','2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_val_data = get_feats_data(['2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(feats_tr_data[0].columns)\n",
    "# x = feats_tr_data[0]['finishing']\n",
    "# y = feats_tr_data[1]\n",
    "# #sns.jointplot(feats_tr_data[0]['sprint_speed'],feats_tr_data[1], kind = 'kde')\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(6, 6))\n",
    "# cmap = sns.cubehelix_palette(as_cmap=True, dark=1, light=0, reverse=True)\n",
    "# sns.kdeplot(x,y , cmap=cmap, n_levels=100, shade=True);\n",
    "\n",
    "# with sns.axes_style(\"white\"):\n",
    "#     sns.jointplot(x=x, y=y, kind=\"hex\", color=\"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "# sample_weights = compute_sample_weight('balanced', y_integers)\n",
    "\n",
    "def keras_1(x_train,y_train,val_tuple):\n",
    "#     from sklearn.utils import compute_class_weight\n",
    "#     classWeight = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "#     classWeight = dict(enumerate(classWeight,1))\n",
    "#     print(classWeight)\n",
    "    \n",
    "    from keras.optimizers import SGD\n",
    "    opt = SGD(lr=0.05)\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,input_dim = x_train.shape[1], activation = 'sigmoid'))\n",
    "    model.add(Dense(200, activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer ='adam',metrics = ['accuracy'])\n",
    "\n",
    "    model.fit(x_train,y_train,epochs = 50, batch_size = 32, validation_data = val_tuple,verbose=0)\n",
    "    print(model.evaluate(val_tuple[0],val_tuple[1]))\n",
    "    return model#.predict(val_tuple[0])\n",
    "   \n",
    "def keras_2(x_train,y_train,val_tuple):\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    from keras.optimizers import SGD\n",
    "    opt = SGD(lr=0.05)\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,input_dim = x_train.shape[1], activation = 'sigmoid'))\n",
    "    model.add(Dense(200, activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer ='adam',metrics = ['accuracy'])\n",
    "\n",
    "    model.fit(x_train,y_train,epochs = 50, batch_size = 32, validation_data = val_tuple)\n",
    "    #print(model.evaluate())\n",
    "    #print(model.metrics)\n",
    "    return model#.predict(val_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select k best\n",
    "\n",
    "feature_selection_evaluation(feats_tr_data, feats_val_data, [5,8,10,14,17,20,27],keras_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_1(feats_tr_data[0],onehot(feats_tr_data[1]),(feats_val_data[0],onehot(feats_val_data[1])))\n",
    "\n",
    "val_pred = model.predict(feats_val_data[0])\n",
    "#inv_val_pred_1 = inv_onehot(feats_pred).reshape(1,-1)[0]\n",
    "#acc/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_test_data = get_feats_data(['2018'])\n",
    "feats_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(feats_test_data[0])\n",
    "inv_test_pred = inv_onehot(test_pred).reshape(1,-1)[0]\n",
    "print(test_pred)\n",
    "#print(inv_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldpos_tr_data = get_fieldpos_data(['2014','2015','2016'])\n",
    "fieldpos_val_data = get_fieldpos_data(['2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldpos_test_data = get_fieldpos_data(['2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras_2(fieldpos_tr_data[0],onehot(fieldpos_tr_data[1]),(fieldpos_val_data[0],onehot(fieldpos_val_data[1])))\n",
    "# print(fieldpos_pred)\n",
    "# inv_pred = inv_onehot(fieldpos_pred).reshape(1,-1)[0]\n",
    "# print(inv_pred)\n",
    "val_pred_2 = model_2.predict(fieldpos_val_data[0])\n",
    "print(val_pred_2)\n",
    "#accuracy_score(inv_pred,fieldpos_val_data[1])\n",
    "# print(model_2)\n",
    "# test_pred_2 = model_2.predict(fieldpos_test_data[0])\n",
    "# inv_test_pred_2 = inv_onehot(test_pred_2).reshape(1,-1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "it = feats_val_data[0].iterrows()\n",
    "\n",
    "for i in range(0,len(feats_val_data[1])):\n",
    "    print(feats_pred[i], fieldpos_pred[i],feats_val_data[1][i],  [feats_pred[i][0] +   fieldpos_pred[i][0],  feats_pred[i][1] + fieldpos_pred[i][1],  feats_pred[i][2] + fieldpos_pred[i][2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "it = feats_val_data[0].iterrows()\n",
    "z = 0\n",
    "for i in range(0,len(feats_val_data[1])):\n",
    "    a = [0,feats_pred[i][0],feats_pred[i][1],feats_pred[i][2],0,fieldpos_pred[i][0], fieldpos_pred[i][1],fieldpos_pred[i][2]]\n",
    "    m = max(a)\n",
    "    i = a.index(m)\n",
    "    if (i)%4 ==feats_val_data[1][i] :\n",
    "        z = z + 1\n",
    "z/len(feats_val_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_table(fixtures, results, total_games):\n",
    "    team_points = {}\n",
    "\n",
    "    for i in range(10):\n",
    "        team_points[fixtures.iloc[i]['HomeTeam']] = 0\n",
    "        team_points[fixtures.iloc[i]['AwayTeam']] = 0\n",
    "\n",
    "    for i in range(total_games):\n",
    "        result = results[i]\n",
    "        fixture = fixtures.iloc[i]\n",
    "        if(result == 1):\n",
    "            team_points[fixture['HomeTeam']] += 3\n",
    "        elif(result == 2):\n",
    "            team_points[fixture['HomeTeam']] += 1\n",
    "            team_points[fixture['AwayTeam']] += 1\n",
    "        elif(result == 3):\n",
    "            team_points[fixture['AwayTeam']] += 3\n",
    "\n",
    "    sorted_team_points = sorted(team_points.items(), key=lambda kv: kv[1])\n",
    "    sorted_team_points.reverse()\n",
    "    return dict(sorted_team_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "fixtures = get_fixtures('2018')\n",
    "#fixtures = fixtures[fixtures['Round Number'] <= 16]\n",
    "fixtures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_table = pd.DataFrame.from_dict(generate_final_table(fixtures, inv_test_pred,380), orient = 'index')\n",
    "final_table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_combine(feats_pred, fieldpos_pred):\n",
    "    times = 0\n",
    "    count = 0\n",
    "    home_wins = 0\n",
    "    final_pred = []\n",
    "    for i in range(0,len(feats_pred)):\n",
    "        #print(fieldpos_test_data[1][i],feats_pred[i], fieldpos_pred[i], [(feats_pred[i][0] +   fieldpos_pred[i][0])/2,  (feats_pred[i][1] + fieldpos_pred[i][1])/2,  (feats_pred[i][2] + fieldpos_pred[i][2])/2])\n",
    "        \n",
    "        final_pred.append([(feats_pred[i][0] +   fieldpos_pred[i][0])/2,  (feats_pred[i][1] + fieldpos_pred[i][1])/2,  (feats_pred[i][2] + fieldpos_pred[i][2])/2])\n",
    "        #a = [(feats_pred[i][0] +  fieldpos_pred[i][0])/2,  (feats_pred[i][1] + fieldpos_pred[i][1])/2,  (feats_pred[i][2] + fieldpos_pred[i][2])/2]\n",
    "        #a = [feats_pred[i][0],  feats_pred[i][1],  feats_pred[i][2] ]\n",
    "        #a = [fieldpos_pred[i][0],  fieldpos_pred[i][1],  fieldpos_pred[i][2] ]\n",
    "\n",
    "#         m = max(a)\n",
    "#         it = a.index(m) + 1\n",
    "#         #predict vs actual\n",
    "#         if it == fieldpos_test_data[1][i]:\n",
    "#             times = times + 1\n",
    "#             if it == 1 or it == 3:\n",
    "#                 home_wins +=1\n",
    "\n",
    "#         count = count + 1\n",
    "#     print(times, count)\n",
    "#     print(times/count)\n",
    "#     print(home_wins/count\n",
    "    return final_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import binary_crossentropy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "combined = ensemble_combine(val_pred,val_pred_2)\n",
    "\n",
    "#binary_crossentropy(np.array(feats_val_data[1]),inv_onehot(combined).reshape(1,-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(inv_onehot(combined).reshape(1,-1)[0])\n",
    "cm = confusion_matrix(feats_val_data[1],inv_onehot(combined).reshape(1,-1)[0])\n",
    "\n",
    "plot_confusion_matrix(cm, classes = [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

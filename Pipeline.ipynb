{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models import keras_1, keras_2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import *\n",
    "from evaluation import *\n",
    "from common import *\n",
    "# train a feats model\n",
    "from gen_feats_data import get_feats_data\n",
    "from gen_fieldpos_data import get_fieldpos_data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, SelectKBest , chi2, mutual_info_classif,SelectPercentile\n",
    "\n",
    "def feature_selection_evaluation(tr_data,val_data,k_values, keras_model):\n",
    "    accuracies = []\n",
    "    \n",
    "    for kval in k_values:\n",
    "        \n",
    "        kbest = SelectKBest( score_func = mutual_info_classif,k = kval)\n",
    "        \n",
    "        feat_sel_tr_data = kbest.fit_transform(tr_data[0],onehot(tr_data[1]))\n",
    "        \n",
    "        feat_sel_val_data = kbest.transform(val_data[0])\n",
    "\n",
    "        #get all the selected features and apply them to the validation data \n",
    "\n",
    "        model = keras_model(feat_sel_tr_data,onehot(tr_data[1]),(feat_sel_val_data,onehot(val_data[1])))\n",
    "        val_accuracy =  model.evaluate(feat_sel_val_data,onehot(val_data[1]))[1] #only accuracy\n",
    "        accuracies.append(val_accuracy)\n",
    "        print(kval, val_accuracy)\n",
    "        # Get idxs of columns to keep\n",
    "        cols = kbest.get_support(indices=True)\n",
    "        # Create new dataframe with only desired columns, or overwrite existing\n",
    "        sel_cols = [tr_data[0].columns[ic] for ic in cols]\n",
    "        print(sel_cols)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, SelectKBest , chi2, mutual_info_classif,SelectPercentile\n",
    "\n",
    "def feature_selection_pca(tr_data,val_data,k_values, keras_model):\n",
    "    accuracies = []\n",
    "    \n",
    "    for kval in k_values:\n",
    "        \n",
    "        kbest = SelectKBest( k = kval)\n",
    "        \n",
    "        feat_sel_tr_data = kbest.fit_transform(tr_data[0],tr_data[1])\n",
    "        \n",
    "        feat_sel_val_data = kbest.transform(val_data[0])\n",
    "\n",
    "        #get all the selected features and apply them to the validation data \n",
    "\n",
    "        model = keras_model(feat_sel_tr_data,onehot(tr_data[1]),(feat_sel_val_data,onehot(val_data[1])))\n",
    "        val_accuracy =  model.evaluate(feat_sel_val_data,onehot(val_data[1]))[1] #only accuracy\n",
    "        accuracies.append(val_accuracy)\n",
    "        print(kval, val_accuracy)\n",
    "        # Get idxs of columns to keep\n",
    "        cols = kbest.get_support()\n",
    "        # Create new dataframe with only desired columns, or overwrite existing\n",
    "        print(cols)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_tr_data = get_feats_data(['2014','2015','2016'])\n",
    "feats_val_data = get_feats_data(['2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feats_tr_data[0].columns)\n",
    "x = feats_tr_data[0]['finishing']\n",
    "y = feats_tr_data[1]\n",
    "#sns.jointplot(feats_tr_data[0]['sprint_speed'],feats_tr_data[1], kind = 'kde')\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "cmap = sns.cubehelix_palette(as_cmap=True, dark=1, light=0, reverse=True)\n",
    "sns.kdeplot(x,y , cmap=cmap, n_levels=100, shade=True);\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    sns.jointplot(x=x, y=y, kind=\"hex\", color=\"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feats_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "# sample_weights = compute_sample_weight('balanced', y_integers)\n",
    "\n",
    "def keras_1(x_train,y_train,val_tuple):\n",
    "#     from sklearn.utils import compute_class_weight\n",
    "#     classWeight = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "#     classWeight = dict(enumerate(classWeight,1))\n",
    "#     print(classWeight)\n",
    "    \n",
    "    from keras.optimizers import SGD\n",
    "    opt = SGD(lr=0.05)\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,input_dim = x_train.shape[1], activation = 'sigmoid'))\n",
    "#     model.add(Dense(200, activation = 'tanh'))\n",
    "#     model.add(Dropout(0.1))\n",
    "#     model.add(Dense(50, activation = 'tanh'))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer ='adam',metrics = ['accuracy'])\n",
    "\n",
    "    model.fit(x_train,y_train,epochs = 50, batch_size = 32, validation_data = val_tuple,verbose=0)\n",
    "    print(model.evaluate(val_tuple[0],val_tuple[1]))\n",
    "    return model#.predict(val_tuple[0])\n",
    "   \n",
    "def keras_2(x_train,y_train,val_tuple):\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    from keras.optimizers import SGD\n",
    "    opt = SGD(lr=0.05)\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,input_dim = x_train.shape[1], activation = 'sigmoid'))\n",
    "    model.add(Dense(200, activation = 'sigmoid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(3, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer ='adam',metrics = ['categorical_crossentropy'])\n",
    "\n",
    "    model.fit(x_train,y_train,epochs = 50, batch_size = 32, validation_data = val_tuple)\n",
    "    #print(model.evaluate())\n",
    "    #print(model.metrics)\n",
    "    return model#.predict(val_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bad input shape (1140, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-5bd46159708d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#select k best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfeature_selection_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats_tr_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeats_val_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeras_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-1a4070e8b577>\u001b[0m in \u001b[0;36mfeature_selection_evaluation\u001b[1;34m(tr_data, val_data, k_values, keras_model)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mkbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mscore_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mfeat_sel_tr_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0monehot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mfeat_sel_val_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[1;32m--> 450\u001b[1;33m                         copy, random_state)\n\u001b[0m",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    246\u001b[0m            \u001b[0mData\u001b[0m \u001b[0mSets\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mPLoS\u001b[0m \u001b[0mONE\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2014.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \"\"\"\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    750\u001b[0m                         dtype=None)\n\u001b[0;32m    751\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (1140, 3)"
     ]
    }
   ],
   "source": [
    "#select k best\n",
    "\n",
    "feature_selection_evaluation(feats_tr_data, feats_val_data, [5,8,14,17,20,27],keras_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_1(feats_tr_data[0],onehot(feats_tr_data[1]),(feats_val_data[0],onehot(feats_val_data[1])))\n",
    "# inv_pred = inv_onehot(feats_pred).reshape(1,-1)[0]\n",
    "# acc = accuracy_score(inv_pred,feats_val_data[1])\n",
    "# #acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_test_data = get_feats_data(['2018'])\n",
    "feats_test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.62609214 0.23520498 0.13944758]\n",
      " [0.14751111 0.24916524 0.67859584]\n",
      " [0.5434143  0.23962684 0.1930917 ]\n",
      " ...\n",
      " [0.5401246  0.24014941 0.1954473 ]\n",
      " [0.65614617 0.2330242  0.12251051]\n",
      " [0.25752464 0.24854277 0.49283305]]\n",
      "[1. 3. 1. 3. 3. 1. 1. 1. 1. 3. 3. 1. 1. 1. 1. 1. 3. 1. 3. 3. 3. 1. 3. 1.\n",
      " 3. 1. 1. 1. 3. 3. 3. 1. 1. 1. 1. 1. 1. 3. 3. 3. 1. 3. 1. 3. 1. 3. 3. 1.\n",
      " 1. 3. 3. 3. 3. 1. 1. 1. 1. 3. 3. 1. 3. 1. 1. 3. 1. 3. 1. 3. 3. 1. 3. 1.\n",
      " 3. 1. 1. 1. 1. 3. 3. 1. 3. 1. 3. 1. 3. 3. 1. 3. 1. 1. 3. 1. 1. 1. 1. 1.\n",
      " 3. 3. 1. 1. 3. 3. 1. 3. 1. 3. 3. 1. 1. 3. 3. 3. 1. 3. 3. 3. 1. 1. 1. 1.\n",
      " 3. 1. 1. 1. 3. 3. 1. 3. 1. 1. 3. 1. 3. 1. 1. 3. 3. 1. 3. 1. 1. 1. 1. 3.\n",
      " 3. 3. 3. 1. 1. 1. 3. 1. 3. 3. 1. 1. 3. 3. 3. 1. 1. 3. 3. 1. 1. 1. 3. 3.\n",
      " 3. 1. 3. 1. 3. 1. 3. 1. 3. 1. 3. 3. 3. 3. 1. 3. 1. 1. 1. 3. 3. 3. 3. 1.\n",
      " 1. 1. 1. 1. 3. 3. 3. 1. 3. 1. 3. 3. 1. 3. 1. 1. 3. 1. 3. 3. 1. 1. 3. 1.\n",
      " 1. 1. 1. 1. 1. 3. 1. 1. 1. 3. 1. 3. 3. 3. 1. 3. 3. 3. 1. 1. 3. 3. 1. 1.\n",
      " 1. 1. 3. 1. 1. 3. 3. 1. 1. 3. 1. 3. 3. 3. 1. 1. 1. 1. 3. 1. 1. 3. 3. 3.\n",
      " 1. 3. 1. 3. 1. 1. 1. 3. 3. 1. 3. 3. 3. 1. 1. 1. 3. 1. 3. 3. 3. 1. 1. 3.\n",
      " 1. 1. 3. 3. 1. 3. 3. 1. 1. 1. 3. 3. 1. 1. 3. 3. 3. 3. 1. 1. 1. 3. 1. 1.\n",
      " 3. 3. 1. 3. 1. 1. 1. 1. 1. 1. 3. 3. 1. 3. 3. 1. 1. 3. 1. 1. 3. 3. 1. 1.\n",
      " 1. 3. 1. 3. 1. 1. 3. 1. 3. 3. 1. 3. 3. 1. 1. 3. 3. 1. 1. 1. 1. 1. 1. 3.\n",
      " 1. 3. 3. 1. 1. 3. 1. 3. 1. 1. 3. 3. 1. 1. 3. 1. 1. 1. 1. 3.]\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(feats_test_data[0])\n",
    "inv_test_pred = inv_onehot(test_pred).reshape(1,-1)[0]\n",
    "print(test_pred)\n",
    "print(inv_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldpos_tr_data = get_fieldpos_data(['2014','2015','2016'])\n",
    "fieldpos_val_data = get_fieldpos_data(['2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldpos_test_data = get_fieldpos_data(['2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras_2(fieldpos_tr_data[0],onehot(fieldpos_tr_data[1]),(fieldpos_val_data[0],onehot(fieldpos_val_data[1])))\n",
    "# print(fieldpos_pred)\n",
    "# inv_pred = inv_onehot(fieldpos_pred).reshape(1,-1)[0]\n",
    "# print(inv_pred)\n",
    "\n",
    "#accuracy_score(inv_pred,fieldpos_val_data[1])\n",
    "print(model_2)\n",
    "test_pred_2 = model_2.predict(fieldpos_test_data[0])\n",
    "inv_test_pred_2 = inv_onehot(test_pred_2).reshape(1,-1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "it = feats_val_data[0].iterrows()\n",
    "\n",
    "for i in range(0,len(feats_val_data[1])):\n",
    "    print(feats_pred[i], fieldpos_pred[i],feats_val_data[1][i],  [feats_pred[i][0] +   fieldpos_pred[i][0],  feats_pred[i][1] + fieldpos_pred[i][1],  feats_pred[i][2] + fieldpos_pred[i][2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "it = feats_val_data[0].iterrows()\n",
    "z = 0\n",
    "for i in range(0,len(feats_val_data[1])):\n",
    "    a = [0,feats_pred[i][0],feats_pred[i][1],feats_pred[i][2],0,fieldpos_pred[i][0], fieldpos_pred[i][1],fieldpos_pred[i][2]]\n",
    "    m = max(a)\n",
    "    i = a.index(m)\n",
    "    if (i)%4 ==feats_val_data[1][i] :\n",
    "        z = z + 1\n",
    "z/len(feats_val_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_table(fixtures, results, total_games):\n",
    "    team_points = {}\n",
    "\n",
    "    for i in range(10):\n",
    "        team_points[fixtures.iloc[i]['HomeTeam']] = 0\n",
    "        team_points[fixtures.iloc[i]['AwayTeam']] = 0\n",
    "\n",
    "    for i in range(total_games):\n",
    "        result = results[i]\n",
    "        fixture = fixtures.iloc[i]\n",
    "        if(result == 1):\n",
    "            team_points[fixture['HomeTeam']] += 3\n",
    "        elif(result == 2):\n",
    "            team_points[fixture['HomeTeam']] += 1\n",
    "            team_points[fixture['AwayTeam']] += 1\n",
    "        elif(result == 3):\n",
    "            team_points[fixture['AwayTeam']] += 3\n",
    "\n",
    "    sorted_team_points = sorted(team_points.items(), key=lambda kv: kv[1])\n",
    "    sorted_team_points.reverse()\n",
    "    return dict(sorted_team_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "fixtures = get_fixtures('2018')\n",
    "#fixtures = fixtures[fixtures['Round Number'] <= 16]\n",
    "fixtures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380,)\n",
      "[1. 3. 1. 1. 3. 1. 1. 1. 1. 3. 3. 1. 1. 1. 1. 1. 3. 1. 3. 3. 3. 1. 3. 1.\n",
      " 3. 1. 1. 1. 3. 1. 3. 1. 1. 1. 1. 1. 1. 3. 3. 3. 1. 3. 1. 3. 1. 3. 3. 1.\n",
      " 1. 3. 1. 1. 3. 1. 1. 1. 1. 3. 3. 1. 3. 1. 1. 3. 1. 3. 1. 3. 3. 1. 3. 1.\n",
      " 3. 1. 1. 1. 1. 3. 3. 1. 3. 1. 3. 1. 3. 3. 1. 3. 1. 1. 3. 1. 1. 1. 1. 1.\n",
      " 3. 3. 1. 1. 3. 3. 1. 3. 1. 3. 3. 1. 1. 3. 3. 3. 1. 3. 3. 3. 1. 1. 1. 1.\n",
      " 3. 1. 1. 1. 3. 3. 1. 3. 1. 1. 3. 1. 3. 1. 1. 3. 3. 1. 3. 1. 1. 1. 1. 3.\n",
      " 3. 3. 3. 1. 1. 1. 3. 1. 3. 3. 1. 1. 3. 3. 3. 1. 1. 3. 3. 1. 1. 1. 3. 3.\n",
      " 3. 1. 3. 1. 1. 1. 3. 1. 1. 1. 3. 3. 3. 3. 1. 3. 1. 1. 1. 3. 3. 3. 3. 1.\n",
      " 1. 1. 1. 1. 3. 3. 3. 1. 3. 1. 3. 1. 1. 3. 1. 1. 3. 1. 1. 3. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 3. 1. 1. 1. 3. 1. 1. 3. 3. 1. 3. 3. 3. 1. 1. 1. 3. 1. 1.\n",
      " 1. 1. 3. 1. 1. 1. 3. 1. 1. 3. 1. 3. 3. 3. 1. 1. 1. 1. 3. 1. 1. 3. 3. 3.\n",
      " 1. 3. 1. 1. 1. 1. 1. 3. 3. 1. 3. 3. 1. 1. 1. 1. 3. 1. 3. 3. 3. 1. 1. 3.\n",
      " 1. 1. 3. 3. 1. 1. 3. 1. 1. 1. 3. 3. 1. 1. 3. 3. 3. 3. 1. 1. 1. 1. 1. 1.\n",
      " 3. 3. 1. 3. 1. 1. 1. 1. 1. 1. 3. 3. 1. 3. 3. 1. 1. 3. 1. 1. 3. 3. 1. 1.\n",
      " 1. 3. 1. 3. 1. 1. 3. 1. 3. 3. 1. 1. 1. 1. 1. 3. 3. 1. 1. 1. 1. 1. 1. 3.\n",
      " 1. 3. 3. 1. 1. 3. 1. 3. 1. 1. 3. 3. 1. 1. 3. 1. 1. 1. 1. 3.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_table = pd.DataFrame.from_dict(generate_final_table(fixtures, inv_test_pred,380), orient = 'index')\n",
    "final_table \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_combine(feats_pred, fieldpos_pred):\n",
    "    times = 0\n",
    "    count = 0\n",
    "    home_wins = 0\n",
    "    final_pred = []\n",
    "    for i in range(0,len(fieldpos_test_data[1])):\n",
    "        #print(fieldpos_test_data[1][i],feats_pred[i], fieldpos_pred[i], [(feats_pred[i][0] +   fieldpos_pred[i][0])/2,  (feats_pred[i][1] + fieldpos_pred[i][1])/2,  (feats_pred[i][2] + fieldpos_pred[i][2])/2])\n",
    "        \n",
    "        final_pred.append((feats_pred[i][0] +   fieldpos_pred[i][0])/2,  (feats_pred[i][1] + fieldpos_pred[i][1])/2,  (feats_pred[i][2] + fieldpos_pred[i][2])/2)\n",
    "        #a = [(feats_pred[i][0] +  fieldpos_pred[i][0])/2,  (feats_pred[i][1] + fieldpos_pred[i][1])/2,  (feats_pred[i][2] + fieldpos_pred[i][2])/2]\n",
    "        #a = [feats_pred[i][0],  feats_pred[i][1],  feats_pred[i][2] ]\n",
    "        #a = [fieldpos_pred[i][0],  fieldpos_pred[i][1],  fieldpos_pred[i][2] ]\n",
    "\n",
    "        m = max(a)\n",
    "        it = a.index(m) + 1\n",
    "        #predict vs actual\n",
    "        if it == fieldpos_test_data[1][i]:\n",
    "            times = times + 1\n",
    "            if it == 1 or it == 3:\n",
    "                home_wins +=1\n",
    "\n",
    "        count = count + 1\n",
    "#     print(times, count)\n",
    "#     print(times/count)\n",
    "#     print(home_wins/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

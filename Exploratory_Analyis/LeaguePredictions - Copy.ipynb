{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as db \n",
    "import pandas as pd\n",
    "conn = db.connect('soccer/database.sqlite')\n",
    "\n",
    "##\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def normalize(df):\n",
    "    for key in df:\n",
    "        if key in x_cols:\n",
    "            mn = df[key].min()\n",
    "            mx = df[key].max()\n",
    "            diff = mx - mn\n",
    "            df[key] = df[key].apply(lambda x : (x-mn)/diff)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_team_name = {}\n",
    "norm_team_name['Man United'] = 'Manchester United'\n",
    "norm_team_name['Man City'] = 'Manchester City'\n",
    "norm_team_name['QPR'] = 'Queens Park Rangers'\n",
    "norm_team_name['West Brom'] = 'West Bromwich Albion'\n",
    "norm_team_name['West Ham'] = 'West Ham United'\n",
    "norm_team_name['Bournemouth'] = 'AFC Bournemouth'\n",
    "\n",
    "year_data = {'2014': 'statbunker-football-stats/Player Stats 2014-15.csv' , \n",
    "             '2015': 'statbunker-football-stats/Player Stats 2015-16.csv' ,\n",
    "             '2016': 'statbunker-football-stats/Player Stats 2016-17.csv'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_players_info(year):\n",
    "    query_str = \"\"\"select  p.player_name,pa2.* from player_attributes pa2, player p where p.player_api_id = pa2.player_api_id and\n",
    "    (pa2.player_api_id, pa2.date) in (\n",
    "    select z.player_api_id, z.date from (\n",
    "    select pa.player_api_id, pa.date, min(abs(strftime('%%s',pa.date) - strftime('%%s','%(year)s-09-01 00:00:00'))) from player_attributes pa, player p \n",
    "                                    where pa.player_api_id = p.player_api_id\n",
    "                                    and strftime('%%s',pa.date) > strftime('%%s','2014-05-14 00:00:00') \n",
    "                                    and pa.date like '%(year)s%%'\n",
    "                                    group by pa.player_api_id ) z )\"\"\"%{'year':year}\n",
    "    \n",
    "    all_player_attrs = pd.read_sql_query(query_str,conn)\n",
    "    \n",
    "    return all_player_attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_player_names(all_players_info):\n",
    "    \n",
    "    for key,value in norm_team_name.items():\n",
    "        all_players_info.loc[lambda df: df['HomeTeam'] == key, 'HomeTeam'] = value\n",
    "        all_players_info.loc[lambda df: df['AwayTeam'] == key, 'AwayTeam'] = value\n",
    "    \n",
    "    return all_players_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_data(year):\n",
    "    ptm = pd.read_csv(year_data[year] , dtype = {'overall_rating':float} )\n",
    "   \n",
    "    ptm = ptm[(ptm['Type Of Goal'] == 'Player') & (ptm['League'] == 'Premier League')]\n",
    "    \n",
    "    all_players_info  = get_all_players_info(year)\n",
    "        \n",
    "    joined = all_players_info.set_index('player_name').join(ptm.set_index('Player'), how='inner')\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team(data, name):\n",
    "    \n",
    "    full_team = data[data['Team'].str.startswith(name)]\n",
    "        \n",
    "    team_agg = {}\n",
    "    \n",
    "    team_df = {}\n",
    "    \n",
    "    df_start = full_team[full_team['Team'] == 'THIS DOES NOT EXIST']\n",
    "    \n",
    "    pos_sel = {'Defender': 4, 'Midfielder': 4, 'Forward': 2, 'Goalkeeper':1}\n",
    "\n",
    "    \n",
    "    \n",
    "#     if (len(df_start[df_start['Position'] == 'Forward']) < 3 ):\n",
    "#         forwards = len(df_start[df_start['Position'] == 'Forward'])\n",
    "#         print(forwards)\n",
    "#         pos_sel['Forward'] = forwards\n",
    "#         pos_sel['Midfielder'] = 6 - forwards\n",
    "\n",
    "    for key,value in pos_sel.items():\n",
    "        \n",
    "        grp = full_team[full_team['Position'] == key].sort_values(by = ['overall_rating'], ascending = False).head(value)\n",
    "        df_start = df_start.append(grp)\n",
    "        avg = grp.mean()\n",
    "        team_agg[key] = avg\n",
    "    \n",
    "    return df_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_attributes(team):\n",
    "    #team[team['Position'] == 'Goalkeeper']['Position'] = 'Defender'\n",
    "    \n",
    "    team.loc[lambda df: df['Position'] == 'Goalkeeper', 'Position'] = 'Defender'\n",
    "       \n",
    "    \n",
    "    g = team.groupby(['Position'] , as_index=False).mean()\n",
    "    #print(g['overall_rating'])\n",
    "    #g = g.reset_index().set_index('index')\n",
    "    \n",
    "    return g.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixtures(year):\n",
    "    f = pd.read_csv('epl-results-19932018/EPL_Set.csv')\n",
    "    f = norm_player_names(f)\n",
    "    \n",
    "    return f[f['Season'].str.startswith(year)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_metrics_2(row, home_attrs,away_attrs,i):\n",
    "    ### D - D , A - A ###\n",
    "    norm_attrs = {}\n",
    "    norm_attrs['Home_Def'] = home_attrs[0]['overall_rating']\n",
    "    norm_attrs['Home_Att'] = home_attrs[1]['overall_rating']\n",
    "    norm_attrs['Home_Mid'] = home_attrs[2]['overall_rating']\n",
    "    \n",
    "    norm_attrs['Away_Def'] = away_attrs[0]['overall_rating']\n",
    "    norm_attrs['Away_Att'] = away_attrs[1]['overall_rating']\n",
    "    norm_attrs['Away_Mid'] = away_attrs[2]['overall_rating']\n",
    "\n",
    "    norm_attrs['Def_Score'] = home_attrs[0]['overall_rating'] - away_attrs[0]['overall_rating']\n",
    "    norm_attrs['Att_Score'] = home_attrs[1]['overall_rating'] - away_attrs[1]['overall_rating']\n",
    "    norm_attrs['Mid_Score'] = home_attrs[2]['overall_rating'] - away_attrs[2]['overall_rating']\n",
    "    norm_attrs['Result'] = 1 if row['FTHG'] - row['FTAG'] > 0  else (-1 if row['FTHG'] - row['FTAG'] < 0 else 0)\n",
    "    \n",
    "    norm_df = pd.DataFrame(norm_attrs, index = [str(i)])\n",
    "    \n",
    "    return norm_df\n",
    "\n",
    "def combine_metrics_1(row,home_attrs,away_attrs,i):\n",
    "    \"\"\" D-A  \"\"\"\n",
    "    norm_attrs = {}\n",
    "    \n",
    "    norm_attrs['Home_Def'] = home_attrs[0]['overall_rating']\n",
    "    norm_attrs['Home_Att'] = home_attrs[1]['overall_rating']\n",
    "    norm_attrs['Home_Mid'] = home_attrs[2]['overall_rating']\n",
    "    \n",
    "    norm_attrs['Away_Def'] = away_attrs[0]['overall_rating']\n",
    "    norm_attrs['Away_Att'] = away_attrs[1]['overall_rating']\n",
    "    norm_attrs['Away_Mid'] = away_attrs[2]['overall_rating']\n",
    "    \n",
    "    norm_attrs['Def_Score'] = home_attrs[0]['overall_rating'] - away_attrs[1]['overall_rating']\n",
    "    norm_attrs['Att_Score'] = home_attrs[1]['overall_rating'] - away_attrs[0]['overall_rating']\n",
    "    norm_attrs['Mid_Score'] = home_attrs[2]['overall_rating'] - away_attrs[2]['overall_rating']\n",
    "    norm_attrs['Result'] = 1 if row['FTHG'] - row['FTAG'] > 0  else (-1 if row['FTHG'] - row['FTAG'] < 0 else 0)\n",
    "    \n",
    "    norm_df = pd.DataFrame(norm_attrs, index = [str(i)])\n",
    "    \n",
    "    return norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_team_data(year):\n",
    "    \n",
    "    data = {}\n",
    "\n",
    "    joined_data = get_full_data(year)\n",
    "\n",
    "    f = get_fixtures(year)\n",
    "    teams = f['HomeTeam'].unique()\n",
    "\n",
    "    for team in teams:\n",
    "        team_data = create_team(joined_data, team)\n",
    "        team_attr = agg_attributes(team_data)\n",
    "        data[team] = (team_data, team_attr)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_normalize(df, attr,column):\n",
    "        \n",
    "    mx = max(df[column])\n",
    "    mn = min(df[column])\n",
    "    diff = (mx) - (mn)\n",
    "    return df[attr].apply(lambda x : x/diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_training_data(years):\n",
    "    \n",
    "    full_res_df = pd.DataFrame()\n",
    "    \n",
    "    for year in years:\n",
    "        \n",
    "        team_store = get_all_team_data(year)\n",
    "        i = 0\n",
    "        res_df = pd.DataFrame()\n",
    "        f = get_fixtures(year)\n",
    "        for key,row in f.iterrows():\n",
    "        #     print(\"MATCHING UP: %s vs %s\"%(row['HomeTeam'], row['AwayTeam']))\n",
    "            home = row['HomeTeam']\n",
    "            away = row['AwayTeam']\n",
    "\n",
    "            home_attrs = team_store[home][1]\n",
    "            away_attrs = team_store[away][1]\n",
    "\n",
    "            res_df = res_df.append(combine_metrics_2(row,home_attrs,away_attrs,i))\n",
    "\n",
    "            i = i + 1\n",
    "        \n",
    "        res_df['Att_Score'] = attr_normalize(res_df, 'Att_Score','Home_Att' )\n",
    "        res_df['Def_Score'] = attr_normalize(res_df, 'Def_Score','Home_Def' )\n",
    "        res_df['Mid_Score'] = attr_normalize(res_df, 'Mid_Score','Home_Mid' )\n",
    "        res_df['Total'] = (res_df['Att_Score'] + res_df['Def_Score'] + res_df['Mid_Score'])/3\n",
    "        res_df.pop('Home_Att')\n",
    "        res_df.pop('Home_Mid')\n",
    "        res_df.pop('Home_Def')\n",
    "        res_df.pop('Away_Att')\n",
    "        res_df.pop('Away_Mid')\n",
    "        res_df.pop('Away_Def')\n",
    "\n",
    "        \n",
    "        full_res_df = full_res_df.append(res_df)\n",
    "\n",
    "    return full_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = construct_training_data(['2014','2015','2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "attribute = 'Total'\n",
    "\n",
    "strong_home_winners = tr_data[(tr_data['Total'] > 0) & (tr_data['Result'] == 1)]\n",
    "\n",
    "strong_home_losers= tr_data[(tr_data['Total'] > 0) & (tr_data['Result'] == -1)]\n",
    "\n",
    "strong_home_draw = tr_data[(tr_data['Total'] > 0) &  (tr_data['Result'] == 0)]\n",
    "\n",
    "\n",
    "strong_away_winners = tr_data[(tr_data['Total'] < 0) & (tr_data['Result'] == 1)]\n",
    "\n",
    "strong_away_losers = tr_data[(tr_data['Total'] < 0) & (tr_data['Result'] == -1)]\n",
    "\n",
    "strong_away_draw = tr_data[(tr_data['Total'] < 0) &  (tr_data['Result'] == 0)]\n",
    "\n",
    "\n",
    "disp_attrs = {'hist': True, 'kde': True, 'norm_hist':True, \"color\" : 'black', 'rug':True}\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(3, 2, figsize=(13, 7), sharex=False)\n",
    "\n",
    "sns.distplot(strong_home_winners[attribute],**disp_attrs, ax = axes[0,0] )\n",
    "axes[0,0].set_title( 'Games where strong home team won - %s of 1140 '%str(len(strong_home_winners['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_home_losers[attribute],**disp_attrs, ax = axes[1,0])\n",
    "axes[1,0].set_title( 'Distribution where strong home team lost - %s of 1140'%str(len(strong_home_losers['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_home_draw[attribute],**disp_attrs, ax = axes[2,0])\n",
    "axes[2,0].set_title( 'Distribution where strong home team drew - %s of 1140'%str(len(strong_home_draw['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_away_winners[attribute],**disp_attrs,ax = axes[0,1] )\n",
    "axes[0,1].set_title( 'Games where strong away teams won - %s of 1140'%str(len(strong_away_winners['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_away_losers[attribute],**disp_attrs, ax = axes[1,1])\n",
    "axes[1,1].set_title( 'Distribution where strong away teams lost - %s of 1140'%str(len(strong_away_losers['Att_Score'])))\n",
    "\n",
    "sns.distplot(strong_away_draw[attribute],**disp_attrs, ax = axes[2,1])\n",
    "axes[2,1].set_title( 'Distribution where strong away team drew - %s of 1140'%str(len(strong_away_draw['Att_Score'])))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# for key, row in tr_data.iterrows():\n",
    "    \n",
    "#     if (row['Def_Score'] > 0 and row['Result'] == 1) or (row['Def_Score'] < 0 and row['Result'] == -1):\n",
    "#         color = ''\n",
    "        \n",
    "#     elif row['Result'] == 0:\n",
    "#         color = ''\n",
    "#     else:\n",
    "#         color = 'bx'\n",
    " \n",
    "#     plt.plot(key, row['Att_Score'], color)\n",
    "\n",
    "# plt.show()\n",
    "# attr = ['Att_Score','Def_Score','Mid_Score']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for a in enumerate(attr):\n",
    "#     print(\"Based on attribute %s\"%a)\n",
    "#     strong_winners_home = tr_data[(tr_data[a] > 0) & (tr_data['Result'] == 1)]\n",
    "#     strong_winners_away = tr_data[(tr_data[a] < 0) & (tr_data['Result'] == -1)]\n",
    "\n",
    "    \n",
    "#     plt.plot(i,tr_data['Att_Score'],'bo',label = 'Test')\n",
    "#     strong_draw_home = tr_data[(tr_data[a] > 0) & (tr_data['Result'] == 0)]\n",
    "#     strong_draw_away = tr_data[(tr_data[a] < 0) & (tr_data['Result'] == 0)]\n",
    "    \n",
    "#     weak_winner_home = tr_data[(tr_data[a] > 0) & (tr_data['Result'] == -1)]\n",
    "#     weak_winner_away = tr_data[(tr_data[a] < 0) & (tr_data['Result'] == 1)]\n",
    " \n",
    "# #     print(len(strong_winners_away) + len(strong_winners_home) )\n",
    "\n",
    "# #     #print(strong_winners_home\n",
    "# #     print(len(strong_draw_home) + len(strong_draw_away))\n",
    "    \n",
    "# #     print(len(weak_winner_away) + len(weak_winner_home) )\n",
    "    \n",
    "    \n",
    "# #plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train,y_train):\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    #Input Layer with 61 inputs corresponding to 61 features \n",
    "    \n",
    "    model.add(Dense(1000,input_dim=3,activation='relu'))\n",
    "    model.add(Dense(500,activation='relu'))\n",
    "    model.add(Dense(300,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "#     model.add(Dense(20,input_dim = 3, activation = 'relu'))\n",
    "\n",
    "#     model.add(Dense(128,activation = 'relu'))\n",
    "\n",
    "#     model.add(Dense(1,activation = 'sigmoid'))\n",
    "  \n",
    "#     #Compiling the model with appropriate parameters\n",
    "#     model.compile(loss = 'mse', optimizer ='adam',metrics = ['accuracy'])\n",
    "\n",
    "    result = model.fit(x_train,y_train,epochs = 50, batch_size = 50)\n",
    "\n",
    "    #Store the model, its average training accuracy and validation accuracy over 10 epochs\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_copy = tr_data.copy()\n",
    "\n",
    "full_copy.pop('Total')\n",
    "full_y = full_copy.pop('Result')\n",
    "full_x = full_copy\n",
    "\n",
    "x_train,te_x,y_train,te_y = train_test_split(full_x, full_y, test_size = 0.25, stratify = full_y)\n",
    "\n",
    "print(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training neural network\n",
    "print(len(x_train))\n",
    "model = create_model(x_train,y_train)\n",
    "#pred_y = model.predict(te_x)\n",
    "score = model.evaluate(te_x,te_y)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm = LinearSVC(C = 128)\n",
    "svm.fit(x_train,y_train)\n",
    "# print(svm.coef_)\n",
    "# print(svm.intercept_)\n",
    "y_pred = svm.predict(te_x)\n",
    "z =accuracy_score(te_y,y_pred)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4, random_state = 5)\n",
    "\n",
    "dt.fit(x_train['Att_Score'].values.reshape(-1,1),y_train)\n",
    "\n",
    "y_pred = dt.predict(te_x['Att_Score'].values.reshape(-1,1))\n",
    "\n",
    "a = accuracy_score(te_y,y_pred)\n",
    "print(a)\n",
    "# print(te_y.values)\n",
    "print(y_pred)\n",
    "\n",
    "confusion_matrix(y_pred, te_y, labels = [1,0,-1])\n",
    "\n",
    "# import graphviz \n",
    "\n",
    "\n",
    "# dot_data = tree.export_graphviz(dt, out_file='test',feature_names = ['Att_Score'] ,class_names = ['0','-1','1'])\n",
    "\n",
    "# graphviz.render('dot','png','test', quiet = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Gaussian NB\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "\n",
    "gnb.fit(x_train['Att_Score'].values.reshape(-1,1),y_train)\n",
    "\n",
    "y_pred = gnb.predict(te_x['Att_Score'].values.reshape(-1,1))\n",
    "\n",
    "ac = accuracy_score(te_y,y_pred)\n",
    "print(ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

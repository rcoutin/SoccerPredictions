{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "attr_cols = ['crossing', 'finishing', 'heading_accuracy','short_passing', 'volleys', 'dribbling', 'free_kick_accuracy',\n",
    "       'long_passing', 'ball_control', 'acceleration', 'sprint_speed',\n",
    "       'agility', 'reactions', 'balance', 'shot_power', 'jumping', 'stamina',\n",
    "       'strength', 'long_shots', 'aggression', 'interceptions', 'positioning',\n",
    "       'vision', 'penalties', 'marking', 'standing_tackle', 'sliding_tackle',\n",
    "       'gk_positioning','gk_reflexes','form']\n",
    "\n",
    "x_cols = [ \"%s_%s\"%(c,attr)  for c in ['h','a'] for attr in attr_cols]\n",
    "x_norm_cols = [ \"%s_%s\"%(c,attr)  for c in ['h','a'] for attr in attr_cols if attr!='form']\n",
    "y_cols = ['Result']\n",
    "\n",
    "full_data = pd.read_csv('Full_Data_feats_ha.csv' )\n",
    "#Finding misclassifications\n",
    "\n",
    "def misclassification_report(df, y_pred, y_test ):\n",
    "    \n",
    "    misclassified = pd.DataFrame()\n",
    "    \n",
    "    for count,value  in enumerate(y_test.iterrows()):\n",
    "        \n",
    "        if y_pred[count]!=int(value[1]['Result']):\n",
    "            new_row = df.iloc[value[0]]\n",
    "            new_row['Predicted'] = y_pred[count]\n",
    "            misclassified = misclassified.append(new_row)\n",
    "    return misclassified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['crossing', 'finishing', 'heading_accuracy', 'short_passing', 'volleys',\n",
      "       'dribbling', 'free_kick_accuracy', 'long_passing', 'ball_control',\n",
      "       'acceleration', 'sprint_speed', 'agility', 'reactions', 'balance',\n",
      "       'shot_power', 'jumping', 'stamina', 'strength', 'long_shots',\n",
      "       'aggression', 'interceptions', 'positioning', 'vision', 'penalties',\n",
      "       'marking', 'standing_tackle', 'sliding_tackle', 'gk_positioning',\n",
      "       'gk_reflexes', 'form'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def normalize(df):\n",
    "    for key in df:\n",
    "        if key in x_norm_cols:\n",
    "            mn = df[key].min()\n",
    "            mx = df[key].max()\n",
    "            diff = mx - mn\n",
    "            df[key] = df[key].apply(lambda x : (x-mn)/diff)\n",
    "    return df\n",
    "\n",
    "tr_data = normalize(full_data)\n",
    "#take difference and store data \n",
    "\n",
    "for i in attr_cols:\n",
    "    tr_data['%s'%i] = tr_data[\"h_%s\"%i] - tr_data[\"a_%s\"%i]\n",
    "    \n",
    "tr_data_diff = tr_data[attr_cols]\n",
    "print(tr_data_diff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "num_features = 10\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "sel_feats = SelectKBest(k = num_features).fit_transform(tr_data_diff,full_data[y_cols])\n",
    "print(sel_feats.shape)\n",
    "\n",
    "x_all = tr_data_diff\n",
    "y_all = full_data[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# comps = 10\n",
    "# pca = PCA(n_components=comps, svd_solver='full')\n",
    "# x_pca = pca.fit_transform(x_all)  \n",
    "# print(x_pca.shape)\n",
    "\n",
    "import numpy as np\n",
    "#One hot encoding the y values \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "results = np.array(full_data['Result'])\n",
    "y_all = onehot_encoder.fit_transform(results.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_all, y_all, test_size = 0.33, random_state = 42, stratify = y_all)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763 377\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 2s 3ms/step - loss: 0.2128 - acc: 0.4404\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 0s 108us/step - loss: 0.2014 - acc: 0.5308\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 0s 105us/step - loss: 0.1934 - acc: 0.5452\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 0s 128us/step - loss: 0.1910 - acc: 0.5596\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 0s 121us/step - loss: 0.1876 - acc: 0.5518\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 0s 105us/step - loss: 0.1844 - acc: 0.5780\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 0s 110us/step - loss: 0.1823 - acc: 0.5531\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 0s 134us/step - loss: 0.1737 - acc: 0.6147\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 0s 116us/step - loss: 0.1717 - acc: 0.6134\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 0s 149us/step - loss: 0.1658 - acc: 0.6317\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 2s 3ms/step - loss: 0.2270 - acc: 0.4246\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 0s 136us/step - loss: 0.2074 - acc: 0.5059\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 0s 121us/step - loss: 0.2050 - acc: 0.5033\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 0s 126us/step - loss: 0.2024 - acc: 0.5007\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 0s 126us/step - loss: 0.2005 - acc: 0.5164\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 0s 131us/step - loss: 0.1995 - acc: 0.5190\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 0s 152us/step - loss: 0.1982 - acc: 0.5242\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 0s 110us/step - loss: 0.1974 - acc: 0.5256\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 0s 136us/step - loss: 0.1960 - acc: 0.5360\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 0s 121us/step - loss: 0.1960 - acc: 0.5308\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "377\n",
      "[[0.6639517  0.2339936  0.10205477]\n",
      " [0.36217472 0.12075533 0.5170699 ]\n",
      " [0.8170004  0.09884423 0.08415536]\n",
      " ...\n",
      " [0.3666444  0.4753389  0.15801665]\n",
      " [0.40665108 0.2234044  0.36994457]\n",
      " [0.44326013 0.08299451 0.47374535]] [[0.62264967 0.2446052  0.13274515]\n",
      " [0.4620666  0.21743056 0.32050285]\n",
      " [0.6964381  0.20064048 0.10292136]\n",
      " ...\n",
      " [0.3629329  0.25832304 0.37874413]\n",
      " [0.45390847 0.27880895 0.26728255]\n",
      " [0.53712666 0.21788594 0.24498734]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "\n",
    "def create_model2(x_train,y_train):\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    #Input Layer with 61 inputs corresponding to 61 features \n",
    "    model.add(Dense(10,input_dim = 30, activation = 'relu'))\n",
    "\n",
    "    model.add(Dense(100,activation = 'relu'))\n",
    "    model.add(Dense(700,activation = 'relu'))\n",
    "    model.add(Dense(123,activation = 'sigmoid'))\n",
    "    model.add(Dense(3,activation = 'softmax'))\n",
    "    \n",
    "    #Compiling the model with appropriate parameters\n",
    "    model.compile(loss = 'mse', optimizer ='adam',metrics = ['accuracy'])\n",
    "\n",
    "    result = model.fit(x_train,y_train,epochs = 10, batch_size = 100)\n",
    "\n",
    "    #Store the model, its average training accuracy and validation accuracy over 10 epochs\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model(x_train,y_train):\n",
    "    \"\"\" Creates a Sequential model made out of Densely connected Neural Network layers. All parameters are configured as per specification for Q4\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    #Input Layer with 61 inputs corresponding to 61 features \n",
    "    model.add(Dense(100,input_dim = 30, activation = 'relu'))\n",
    "\n",
    "    model.add(Dense(500,activation = 'relu'))\n",
    "    model.add(Dense(200,activation = 'sigmoid'))\n",
    "    model.add(Dense(3,activation = 'softmax'))\n",
    "    \n",
    "    #Compiling the model with appropriate parameters\n",
    "    model.compile(loss = 'mse', optimizer ='nadam',metrics = ['accuracy'])\n",
    "\n",
    "    result = model.fit(x_train,y_train,epochs = 10, batch_size = 100)\n",
    "\n",
    "    #Store the model, its average training accuracy and validation accuracy over 10 epochs\n",
    "\n",
    "    return model\n",
    "\n",
    "#Training neural network\n",
    "print(len(x_train),len(x_test))\n",
    "model = create_model(x_train,y_train)\n",
    "model2 = create_model2(x_train,y_train)\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "pred_y1 = model.predict(x_test)\n",
    "pred_y2 = model2.predict(x_test)\n",
    "print(len(pred_y1))\n",
    "print(pred_y1,pred_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5092838196286472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "new_pred = []\n",
    "\n",
    "for i in range(0,len(pred_y1)):\n",
    "    cur_pred = []\n",
    "    for j in range(0,3):\n",
    "        \n",
    "        cur_pred.append((pred_y1[i][j] + pred_y2[i][j]))\n",
    "    new_pred.append(cur_pred)\n",
    "    \n",
    "inv = onehot_encoder.inverse_transform(new_pred)\n",
    "\n",
    "y_test_inv =  onehot_encoder.inverse_transform(y_test)\n",
    "\n",
    "inv_pred = inv.reshape(1,-1)[0]\n",
    "\n",
    "a = accuracy_score(y_test_inv,inv_pred)\n",
    "print(a)\n",
    "# #Training linear regression on the goal difference \n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import math\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(x_train,y_train['Goal_Diff'])\n",
    "# y_pred = lr.predict(x_test[x_cols])\n",
    "# goals = [math.ceil(value) for value in y_pred]\n",
    "\n",
    "# pred_res = [1 if value > 0 else (-1 if value < 0 else 0) for value in goals]\n",
    "# print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train SVM\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "svm = LinearSVC(C = 0.25, loss = 'hinge',penalty = 'l2')\n",
    "svm.fit(x_train,y_train)\n",
    "# print(svm.coef_)\n",
    "# print(svm.intercept_)\n",
    "y_pred = svm.predict(x_test)\n",
    "z =accuracy_score(y_test,y_pred)\n",
    "print(z)\n",
    "print(y_pred)\n",
    "mc = misclassification_report(full_data,y_pred,y_test)\n",
    "print(mc[x_cols + y_cols + ['Predicted']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = 'gini', max_depth = 4)\n",
    "\n",
    "dt.fit(x_train,y_train)\n",
    "\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "#y_test_synth = [-1 if total < 0 else (1 if total > 0 else 0) for total in x_test['Total'].values] \n",
    "\n",
    "a = accuracy_score(y_test,y_pred)\n",
    "print(a)\n",
    "# print(te_y.values)\n",
    "#mc = misclassification_report(full_data, y_pred,y_test)\n",
    "#print(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "knn_pred = knn.predict(x_test)\n",
    "ak = accuracy_score(x_test,knn_pred)\n",
    "\n",
    "print(ak)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
